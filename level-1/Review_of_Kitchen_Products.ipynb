{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dataframe Basics"
      ],
      "metadata": {
        "id": "Vv16HppWUeva"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\r\n",
        "# For example:\r\n",
        "# spark_version = 'spark-3.2.1'\r\n",
        "spark_version = 'spark-3.2.1'\r\n",
        "os.environ['SPARK_VERSION']=spark_version\r\n",
        "\r\n",
        "# Install Spark and Java\r\n",
        "!apt-get update\r\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "\r\n",
        "# Set Environment Variables\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n",
        "\r\n",
        "# Start a SparkSession\r\n",
        "import findspark\r\n",
        "findspark.init()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 88.7 kB] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1sd9SzuUvob",
        "outputId": "054e9179-1632-44af-ef42-45630ba1f749"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-06 23:04:23--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar.2’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  5.74MB/s    in 0.2s    \n",
            "\n",
            "2022-03-06 23:04:23 (5.74 MB/s) - ‘postgresql-42.2.9.jar.2’ saved [914037/914037]\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIE3kIpLXnve",
        "outputId": "8afd74dc-ca56-4dd8-a7e2-92677ece5f9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Start Spark session\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "spark = SparkSession.builder.appName(\"DataFrameBasics\").config(\"spark.jars\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ],
      "outputs": [],
      "metadata": {
        "id": "nPRmMt8FVirP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Read in data from S3 Buckets\r\n",
        "from pyspark import SparkFiles\r\n",
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz\"\r\n",
        "spark.sparkContext.addFile(url)\r\n",
        "df = spark.read.csv(SparkFiles.get(\"amazon_reviews_us_Kitchen_v1_00.tsv.gz\"), sep=\"\\t\", header=True, quote=\"\")\r\n",
        "\r\n",
        "# Show DataFrame\r\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "|         US|   37000337|R3DT59XH7HXR9K|B00303FI0G|     529320574|Arthur Court Pape...|         Kitchen|          5|            0|          0|   N|                Y|Beautiful. Looks ...|Beautiful.  Looks...| 2015-08-31|\n",
            "|         US|   15272914|R1LFS11BNASSU8|B00JCZKZN6|     274237558|Olde Thompson Bav...|         Kitchen|          5|            0|          1|   N|                Y| Awesome & Self-ness|I personally have...| 2015-08-31|\n",
            "|         US|   36137863|R296RT05AG0AF6|B00JLIKA5C|     544675303|Progressive Inter...|         Kitchen|          5|            0|          0|   N|                Y|Fabulous and wort...|Fabulous and wort...| 2015-08-31|\n",
            "|         US|   43311049|R3V37XDZ7ZCI3L|B000GBNB8G|     491599489|Zyliss Jumbo Garl...|         Kitchen|          5|            0|          1|   N|                Y|          Five Stars|A must if you lov...| 2015-08-31|\n",
            "|         US|   13763148|R14GU232NQFYX2|B00VJ5KX9S|     353790155|1 X Premier Pizza...|         Kitchen|          5|            0|          0|   N|                Y|     Better than sex|Worth every penny...| 2015-08-31|\n",
            "|         US|   19009420| RZQH4V7L2O1PL|B00HYB5YY0|     432241873|       CHEF Aluminum|         Kitchen|          1|            1|          1|   N|                Y|Does not work on ...|The description s...| 2015-08-31|\n",
            "|         US|   40599388|R1F8JMOSPJ3KO7|B000HEBAV2|     584680984|Presto Dual Profr...|         Kitchen|          5|            0|          0|   N|                Y|Awesome! First fr...|Awesome! First fr...| 2015-08-31|\n",
            "|         US|   22719359|R1ZISGY2BWW4Z5|B0012DS4GG|     772637306|Rubbermaid Produc...|         Kitchen|          5|            0|          0|   N|                Y|          Five Stars|Very good item. Q...| 2015-08-31|\n",
            "|         US|   47478640|R17PW4I3AE5WZW|B00FLQ4EE6|     755416578|Cuisinart 12-Piec...|         Kitchen|          5|            0|          0|   N|                Y|          Five Stars|sharp and look great| 2015-08-31|\n",
            "|         US|   34195504|R3D93G1KTP6A8P|B00DBS9OTG|     648762742|Kegco 6\" Stainles...|         Kitchen|          3|            0|          0|   N|                Y|         Three Stars|Should have come ...| 2015-08-31|\n",
            "|         US|   19100570|R18TQIW1NKPUNU|B00AN9UJ68|     495720940|Cuisinart Smart S...|         Kitchen|          5|            0|          0|   N|                Y|          Five Stars|  my friend loves it| 2015-08-31|\n",
            "|         US|   10299811|R34KUNL21WU248|B00L2P0KNO|      41330497|Searzall Torch At...|         Kitchen|          4|            0|          0|   N|                Y|          Four Stars|works as expected...| 2015-08-31|\n",
            "|         US|   32687006|R2YA1ZA53X12IN|B00NQOJQXY|     191893454|Wilton 1512-1664 ...|         Kitchen|          5|            0|          0|   N|                Y|               great|               great| 2015-08-31|\n",
            "|         US|   43260893|R2ZD1IGC9UU55X|B00080QE1Q|     277442428|Magnalite Classic...|         Kitchen|          5|            1|          1|   N|                Y|         Great Pots!|Fantastic product...| 2015-08-31|\n",
            "|         US|    8067227| R9J2YMVZTUVZ7|B009VU17ZM|     414077276|Sun's Tea(TM) 20o...|         Kitchen|          5|            0|          0|   N|                Y|          Five Stars|Work great, well ...| 2015-08-31|\n",
            "|         US|   18139929|R2UUXJ0WQR0CNI|B00MY71KO2|     138697457|Adventure Time Be...|         Kitchen|          4|            0|          0|   N|                Y|              So big|holds a loooot of...| 2015-08-31|\n",
            "|         US|   12282702|R3S9QICITG73JZ|B00A6N18CK|      48180946|DecoBros 3 Tier D...|         Kitchen|          5|            0|          0|   N|                Y|It looks nice & n...|The DecoBros K cu...| 2015-08-31|\n",
            "|         US|   38649737|R3LISNJHS64PDA|B00AB8NOLS|      67759108|Brita Water Filte...|         Kitchen|          4|            0|          0|   N|                Y|          Four Stars| Met my expectations| 2015-08-31|\n",
            "|         US|   33460969|R28RB82UG4RDD5|B00FB4UPA0|      10711472|Nifty Home 24 K-C...|         Kitchen|          5|           20|         20|   N|                Y| Saves counter space|Fits under my ful...| 2015-08-31|\n",
            "|         US|   40274860|R3H0PRVII5991X|B00YMHBQ0A|     618617346|Eoonfirst Snoopy ...|         Kitchen|          5|            0|          0|   N|                Y|          Five Stars|            Love it!| 2015-08-31|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVW7jBoKUeve",
        "outputId": "7db5776d-c127-459a-b8ab-1cf19f699654"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df.count()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4880466"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNMycuA6B7Oh",
        "outputId": "f20fa628-a916-4b23-9645-1fdb6085fd13"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from pyspark.sql.functions import col\r\n",
        "df_review_id_table = df.select(['review_id','customer_id','product_id','product_parent','review_date']).distinct()\r\n",
        "df_review_id_table = (df_review_id_table\r\n",
        "                      .withColumn(\"customer_id\", col(\"customer_id\").cast(\"int\"))\r\n",
        "                      .withColumn(\"product_parent\", col(\"product_parent\").cast(\"int\"))\r\n",
        "                      .withColumn(\"review_date\", col(\"review_date\").cast(\"date\")))\r\n",
        "df_review_id_table.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- customer_id: integer (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_parent: integer (nullable = true)\n",
            " |-- review_date: date (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOj-z65ZXNzX",
        "outputId": "6fc4ee23-4f3b-406d-d39e-ec0ccf1109fc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_review_id_table.count()\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4880466"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTF0Nm-pIqj5",
        "outputId": "43ae5ec7-64f1-47ce-ada3-11419a0342bd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_review_id_table.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|     review_id|customer_id|product_id|product_parent|review_date|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "|R1003WQ2N568UJ|   30984122|B000HCJX2C|     561470701| 2015-07-16|\n",
            "|R1004EZA3OASMT|   15509407|B0009YYQ4S|     455866213| 2011-12-14|\n",
            "|R100EXNK731LTK|   37164434|B0038U5WO8|     233057226| 2015-05-25|\n",
            "|R100PQSJMOLWP0|   26963189|B001ICPAZE|     709838409| 2011-12-28|\n",
            "|R10168116JX8X2|   30974720|B0018CG2EC|     500296269| 2013-11-12|\n",
            "|R10173AGXELGVQ|   33160607|B002DX8QNU|     602831505| 2015-08-28|\n",
            "|R101EV570FB01A|   12321022|B00PUVABGC|     298139833| 2015-03-26|\n",
            "|R101JMABBJBX6U|   51876859|B000W5SLB8|     956903177| 2014-05-03|\n",
            "|R102BUG3QZXMY8|   11142660|B001MUPGQ0|     266396365| 2014-04-16|\n",
            "|R102OI838NN3Z7|   11056168|B000YDUAMQ|     180607962| 2014-01-18|\n",
            "|R102VGUEHU4MVS|   26684756|B0018CE8LQ|     855508227| 2014-07-16|\n",
            "|R103E8CGPOZD6B|    8996047|B0053AS5VS|     840020528| 2014-01-02|\n",
            "|R10492BU3YOKJC|   20427396|B005ELC85U|     686893631| 2014-05-15|\n",
            "|R104GXFZSUJO92|   24506217|B001HRLYUA|     485828897| 2014-11-10|\n",
            "|R104QVUTCZ9ZZL|   42677900|B006FM1I8U|     724823814| 2013-12-31|\n",
            "|R104ZP6J6H31B5|   41787384|B00OLXO6A2|     762490967| 2015-03-16|\n",
            "|R105LYUYQK5UM9|    8240859|B005NK5DEU|      84171195| 2015-03-14|\n",
            "|R106T3P5KAHD1X|   28316223|B008MFFG3Q|     587778826| 2015-07-10|\n",
            "|R106ZYACRIV9DP|   12303507|B007KLK9WQ|      43939939| 2014-02-12|\n",
            "|R107EHF9K652J3|   52195109|B0002AQQ56|     604525406| 2014-08-15|\n",
            "+--------------+-----------+----------+--------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwvP8i6lnezR",
        "outputId": "29b898b3-d436-4124-be77-8dc48307cafe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_products = df.select(['product_id','product_title']).distinct()\r\n",
        "df_products.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_title: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnmBLtJfoMkN",
        "outputId": "bc952e06-2eba-4943-c5bb-6fc61a3bcea1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "df_products.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|product_id|       product_title|\n",
            "+----------+--------------------+\n",
            "|B004NWK4W0|Wildkin Pink Leop...|\n",
            "|B00IE70YFC|Wilton 415-2178 3...|\n",
            "|B00004W499|George Foreman GG...|\n",
            "|B000Q945FG|BIA Cordon Bleu B...|\n",
            "|B007WTOIPA|Clorox Sales Co B...|\n",
            "|B006IC09P0|Utenlid Acrylic R...|\n",
            "|B00CDSU2MI|2000 Diamond Tabl...|\n",
            "|B000WJMTNA|OXO Good Grips St...|\n",
            "|B00DYRI13O|Reed & Barton 148...|\n",
            "|B005FPD67Y|     Ergo Chef Tongs|\n",
            "|B00JLA6POU|TeChef - Art Pan ...|\n",
            "|B00FN3P7X4|Hamilton Beach 1....|\n",
            "|B000UVHUCU|KitchenAid Ultra ...|\n",
            "|B00IZCWYR2|PackIt Freezable ...|\n",
            "|B0105V7VS2|Top Rated Lemon S...|\n",
            "|B002P667TU|Browne (22126P) 6...|\n",
            "|B00KIYWDTO|Wolfgang Puck Pre...|\n",
            "|B00004S9EJ|Cuisinart DLC-8SY...|\n",
            "|B00D19SSE2|Ozeri Serafino Do...|\n",
            "|B00JV8PTYY|Thermos 12 Ounce ...|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bv4i9hhmQAK",
        "outputId": "9c56ca24-f998-4543-b621-426fd7a089b0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#df_customers = df_review_id_table.groupBy(\"customer_id\").count().withColumnRenamed('count','customer_count')\r\n",
        "#df_customers.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "X5kv45kpCb9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Configure settings for RDS\r\n",
        "mode = \"append\"\r\n",
        "jdbc_url=\"jdbc:postgresql://mypostgresdb.cvhifjxfcutl.us-east-1.rds.amazonaws.com:5432/my_data_class_db\"\r\n",
        "config = {\"user\":\"user\", \r\n",
        "          \"password\": \"password\", \r\n",
        "          \"driver\":\"org.postgresql.Driver\"}\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "AcwFYJdW7_MM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Write DataFrame to table in RDS \r\n",
        "\r\n",
        "df_review_id_table.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)\r\n",
        "df_products.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)\r\n",
        "#df_customers.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-760647873c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_review_id_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'review_id_table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjdbc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'products'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#df_customers.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjdbc\u001b[0;34m(self, url, table, mode, properties)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mjprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjdbc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o490.jdbc.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 190.0 failed 1 times, most recent failure: Lost task 0.0 in stage 190.0 (TID 146) (14044dc2804e executor driver): java.sql.BatchUpdateException: Batch entry 444 INSERT INTO products (\"product_id\",\"product_title\") VALUES ('B002R0EZNO','IRIS Airtight Food Storage Container') was aborted: ERROR: duplicate key value violates unique constraint \"products_pkey\"\n  Detail: Key (product_id)=(B002R0EZNO) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:153)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2242)\n\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1357)\n\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1382)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:494)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:850)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:873)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1562)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:728)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2254)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"products_pkey\"\n  Detail: Key (product_id)=(B002R0EZNO) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2505)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2241)\n\t... 20 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1020)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1018)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:893)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:69)\n\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:745)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.sql.BatchUpdateException: Batch entry 444 INSERT INTO products (\"product_id\",\"product_title\") VALUES ('B002R0EZNO','IRIS Airtight Food Storage Container') was aborted: ERROR: duplicate key value violates unique constraint \"products_pkey\"\n  Detail: Key (product_id)=(B002R0EZNO) already exists.  Call getNextException to see other errors in the batch.\n\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:153)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2242)\n\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1357)\n\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1382)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:494)\n\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:850)\n\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:873)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1562)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:728)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:895)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:893)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1020)\n\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1020)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2254)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"products_pkey\"\n  Detail: Key (product_id)=(B002R0EZNO) already exists.\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2505)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2241)\n\t... 20 more\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7UCU-1xdNM7y",
        "outputId": "28c8d65c-f394-4f6f-f557-e44e75a5a9cb"
      }
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [],
      "name": "Review of Kitchen Products.ipynb",
      "provenance": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "nbpresent": {
      "slides": {},
      "themes": {
        "default": "0535adbc-b74f-46cc-9cd6-4eabe2477c8e",
        "theme": {
          "0535adbc-b74f-46cc-9cd6-4eabe2477c8e": {
            "backgrounds": {
              "backgroundColor": {
                "background-color": "backgroundColor",
                "id": "backgroundColor"
              }
            },
            "id": "0535adbc-b74f-46cc-9cd6-4eabe2477c8e",
            "palette": {
              "backgroundColor": {
                "id": "backgroundColor",
                "rgb": [
                  43,
                  43,
                  43
                ]
              },
              "headingColor": {
                "id": "headingColor",
                "rgb": [
                  238,
                  238,
                  238
                ]
              },
              "linkColor": {
                "id": "linkColor",
                "rgb": [
                  19,
                  218,
                  236
                ]
              },
              "mainColor": {
                "id": "mainColor",
                "rgb": [
                  238,
                  238,
                  238
                ]
              }
            },
            "rules": {
              "a": {
                "color": "linkColor"
              },
              "h1": {
                "color": "headingColor",
                "font-family": "Oswald",
                "font-size": 7
              },
              "h2": {
                "color": "headingColor",
                "font-family": "Oswald",
                "font-size": 5
              },
              "h3": {
                "color": "headingColor",
                "font-family": "Oswald",
                "font-size": 3.75
              },
              "h4": {
                "color": "headingColor",
                "font-family": "Oswald",
                "font-size": 3
              },
              "h5": {
                "color": "headingColor",
                "font-family": "Oswald"
              },
              "h6": {
                "color": "headingColor",
                "font-family": "Oswald"
              },
              "h7": {
                "color": "headingColor",
                "font-family": "Oswald"
              },
              "li": {
                "color": "mainColor",
                "font-family": "Lato",
                "font-size": 5
              },
              "p": {
                "color": "mainColor",
                "font-family": "Lato",
                "font-size": 5
              }
            },
            "text-base": {
              "color": "mainColor",
              "font-family": "Lato",
              "font-size": 5
            }
          },
          "cc59980f-cb69-400a-b63a-1fb85ca73c8a": {
            "backgrounds": {
              "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
                "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
                "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
              }
            },
            "id": "cc59980f-cb69-400a-b63a-1fb85ca73c8a",
            "palette": {
              "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
                "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
                "rgb": [
                  252,
                  252,
                  252
                ]
              },
              "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
                "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
                "rgb": [
                  68,
                  68,
                  68
                ]
              },
              "50f92c45-a630-455b-aec3-788680ec7410": {
                "id": "50f92c45-a630-455b-aec3-788680ec7410",
                "rgb": [
                  197,
                  226,
                  245
                ]
              },
              "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
                "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "rgb": [
                  43,
                  126,
                  184
                ]
              },
              "efa7f048-9acb-414c-8b04-a26811511a21": {
                "id": "efa7f048-9acb-414c-8b04-a26811511a21",
                "rgb": [
                  25.118061674008803,
                  73.60176211453744,
                  107.4819383259912
                ]
              }
            },
            "rules": {
              "a": {
                "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
              },
              "blockquote": {
                "color": "50f92c45-a630-455b-aec3-788680ec7410",
                "font-size": 3
              },
              "code": {
                "font-family": "Anonymous Pro"
              },
              "h1": {
                "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
                "font-family": "Merriweather",
                "font-size": 8
              },
              "h2": {
                "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
                "font-family": "Merriweather",
                "font-size": 6
              },
              "h3": {
                "color": "50f92c45-a630-455b-aec3-788680ec7410",
                "font-family": "Lato",
                "font-size": 5.5
              },
              "h4": {
                "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
                "font-family": "Lato",
                "font-size": 5
              },
              "h5": {
                "font-family": "Lato"
              },
              "h6": {
                "font-family": "Lato"
              },
              "h7": {
                "font-family": "Lato"
              },
              "li": {
                "color": "50f92c45-a630-455b-aec3-788680ec7410",
                "font-size": 3.25
              },
              "pre": {
                "font-family": "Anonymous Pro",
                "font-size": 4
              }
            },
            "text-base": {
              "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
              "font-family": "Lato",
              "font-size": 4
            }
          }
        }
      }
    },
    "nteract": {
      "version": "0.10.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}